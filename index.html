<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Research Website</title>
    <link rel="stylesheet" type="text/css" href="style.css">
</head>
<body>
    <h1>5 Milestones of Computer Science</h1>
    <ul>
        <div class="one"><li><span>Leibniz and the Binary System</span>
            <ul>
                <li>
                    While the <i>binary system</i> has evidence of the creation of the idea surrounding it, it was Leibniz who really helped put together a working system. In a <i>binary system</i>, there are only two possible states, on and off, represented by the symbols 1 and 0. Signals and regular pulses are sent through a transistor to allow the passage of pulses or block them. Using the <i>binary system</i>, you can actually represent the decimal numbers, 0-9, by incorporating 
                    four binary digits or bits. So <a href="https://www.mvorganizing.org/what-is-the-importance-of-binary-system-in-computers/#:~:text=Computers%20use%20binary%20%E2%80%93%20the%20digits%200%20and,the%20on%20and%20off%20states%20of%20a%20transistor.">What is the importance of binary numbers in today’s life?</a>The purpose of using binary code in computers is to store data because the computers can only read an on or off charge. The input and output speed of conversion 
                    of data in this system than in others, but it can become significantly slower when working with a variety of integers. Binary is useful and can help you understand the native size and shape of numbers inside computers. It also uses its system to solve complex problems related to mechanical functions of computers and creating cost effective designs. As it is known, the binary system uses two symbols compared to ten symbols like in the decimal system. The reason for 
                    this very simple system’s continued existence in modern technology is that it is easy to implement current electronic technology with. There are, of course other numeric systems. They are the decimal number system, octo number system, and hexadecimal number system. They are the base-10, base-8, and base-16 number systems, respectively.<br>
                    <a href="https://www.britannica.com/technology/binary-code">
                        <img src="https://images.wisegeek.com/green-lit-numbers.jpg">
                    </a>
                </li>
            </ul>
        </li></div>
        <div class="two"><li><span>Alan Turing and the Enigma Machine</span>
            <ul>
                <li>
                    It’s not very likely that you are familiar with Alan Turing unless you a big fan of Benedict Cumberbatch’s period and historical movies. The actual story that the movie is based off of is quite an important detail in the history of computer science. Alan Turing is known for his contributions as a computer pioneer for our modern age of computer technology and artificial science, though neither of these things existed before or during his time. Further background on 
                    the brilliant Turing shows that he created a test for computers, which none have yet passed, called the Turing Test. It tests the ability of a computer to fool a human judge by replicating a conversation in which the judge is blind as to what is human and what is the computer. Of all his accomplishments, he is best known for his work that took place during the Second World War, the <i>ENIGMA</i> machine. This giant machine Turing worked on helped to crack the codes 
                    and ciphers sent by the German army during the war, known as<i> ENIGMAS</i>i>. They were double coded messages meaning that the original text was coded, then the encrypted text was coded as well. He was quite successful during the years of 1941-1943 when he was able to help British Naval ships stay clear of German U-Boats. He is even credited with helping the tragic war keep from dragging longer than necessary. However, during his lifetime, he was not recognized for 
                    the work he did as his work was not to be accessible to the public until the 1970s.<br>
                    <a href="https://www.cia.gov/stories/story/the-enigma-of-alan-turing/">
                        <img src="https://www.cia.gov/static/6d564431d95d919944010e0e622b6235/0cbe2/Enigma2_tweet.jpg">
                    </a>
                </li>
            </ul>
        </li></div>
        <div class="three"><li><span>Grace Hopper and COBOL</span>
            <ul>
                <li>
                    What is <i>COBOL?</i> The acronym stands for Common Business Oriented Language. Who made it and what are its uses? Grace Hopper, a Vassar and Yale graduate of physics and mathematics and temporary part of the NAVY during the Second World War, worked with a small research team on the Bureau of Ordnance Computation Project. She became very familiar with the electromechanical computing machine she was using to compute coefficients of the arc tangent series. She was 
                    so familiar with the machine that she wrote a 500 page manual on its operations. Finding herself at home in the world of coding, Hopper worked on Marks I and II, then joined the Eckert-Mauchly Corporation which helped her pave her way towards inventing <i>COBOL.</i> She was able to invent the compiler which could translate English language instructions into the coding or base language of any target computer. After becoming the director of automatic programming, 
                    she oversaw the specification of <i>COBOL</i>, and by the late 1950s, it was up and running and ready for use on business computers. The business described here being finance, human resources, insurance companies, and many more. In addition, its uses extend to programming applications for businesses, government, and military. Despite being considered a high or high level language, it is fairly easy to understand since it is mostly based off of the English language. 
                    The reason that <i>COBOL</i> is still around is because it still holds files from its early days, so programmers going into these types of positions should familiarize themselves with it.<br>
                <a href="https://sykes007.wordpress.com/2014/04/18/grace-hopper-cobol-common-business-oriented-language/#:~:text=Grace%20Hopper%20will%20always%20be%20remembered%20for%20her,Bush.%20She%20received%20honorary%20degrees%20from%20thirty%20universities.">
                    <img src="https://sykes007.files.wordpress.com/2014/04/hopper-computer.jpg">
                </a>
                </li>
            </ul>
        </li></div>
        <div class="four"><li><span>The Microprocessor</span>
            <ul>
                <li>
                    In the early 1970s, the company known as Intel came out with the world’s first ever single chip <i>microprocessor</i>. Known as the Intel 4004, the chip took all of the parts necessary for the computer to think, like the CPU, central processing unit, and input and output controls, and shrunk them so they’d fit on a tiny chip. Now inanimate objects could have intelligence programmed into everything. For the company that came up with the product, its two founders were
                     referred to as “Fairchildren” for they left the engineering company they were a part of to set out on a new venture. Robert Noyce and Gordon Moore had done enough to garner the attention of a venture capitalist who raised 2.5 million dollars in funds in order to back them. The name of the company was a decidedly better option than the combination of their last names which had already been taken as an option, so their company became Intel which is short for “integrated
                      electronics”. The idea for the <i>microprocessor</i> rose from the need for 12 separate custom chips, each for a different feature or control. The downside was that the company was not yet where it had the manpower needed for that project available, so the need for one small chip that did it all brought us the <i>microprocessor</i>. When finally completed after nine months, the chip was 1/8 inch by 1/6 inch and had the power of the ENIAC, which for those unfamiliar, 
                    took up 3000 cubic feet.<br>
                <a href=""><img src="https://www.thoughtco.com/thmb/gQ9fbTYhwu_Lyxp3BzwAJYj7M9I=/768x0/filters:no_upscale():max_bytes(150000):strip_icc():format(webp)/16387184545_5a8001079d_k-58e6812e3df78c5162075a9c.jpg"></a></li>
            </ul>
        </li></div>
        <div class="five"><li><span>The World Wide Web</span>
            <ul>
                <li>
                    We’re familiar with the Internet today and how it works on mobile devices, connecting countless people all over the world. But the <i>World Wide Web</i> is something a few years older than what most people under the age of 30 are familiar with. The <i>World Wide Web</i> is the networked information available universally and it represents the extent of human knowledge. Its creator was Sir Tim Berners-Lee. As far as features of the web, Sir Tim Berners-Lee also came up 
                    with the fundamental technologies still used today. HTML, also known as HyperText Markup Language, formats the language for the web. Known now as the URL, formerly URI, the Uniform Resource Locator is able to find specific resources on the internet. HTTP, also known as Hypertext Transfer Protocol, retrieves linked sources from across the internet. Here are some ideas of the early technology sector that are now reaching beyond the digital world. Decentralization, 
                    non-discrimination, bottom-up design, universality, and consensus. These mean no controlling power over your head, principles of equity (Net Neutrality), development in full view with expected participation from the public, protocols involving common computer languages, and unanimous agreement among those creating standards. It is used today by over 50% of the population, and I use it every day, almost all day to connect with classmates, teachers, friends, family, 
                    anyone and everyone. I haven’t known a life without it, and that much I am glad for. How else would I be able to chat with my friend in Spain or speak with my grandmother in Colombia on a regular basis if the <i>World Wide Web</i> didn't exist? <br>
                    <a href="https://webfoundation.org/about/vision/history-of-the-web/">
                        <img src="https://th.bing.com/th/id/R.0fc95933b253c1611b1209740ade2207?rik=sRs89bHaPB44WQ&pid=ImgRaw&r=0">
                    </a>
                </li>
            </ul>
        </li></div>
    </ul>
    <table border="4">
        <thead>
            <th>Leibniz and the Binary System</th>
            <th>Alan Turing and the Enigma Machine</th>
            <th>Grace Hopper and COBOL</th>
            <th>The Microprocessor</th>
            <th>The World Wide Web</th>
        </thead>
        <tr>
            <td>1600s</td>
            <td>Early 1940s</td>
            <td>Late 1950s</td>
            <td>Early 1970s</td>
            <td>Late 1980s</td>
        </tr>
    </table>
</body>
</html>